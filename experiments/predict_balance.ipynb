{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>balancing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  idx  balancing\n",
       "0           0    0       1.50\n",
       "1           1    1       2.00\n",
       "2           2    2       1.25\n",
       "3           3    3       2.00\n",
       "4           4    4       2.00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"balancing\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    39\n",
       "idx           39\n",
       "balancing     39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"balancing\"] == 1.5].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"balancing1\"] = data[\"balancing\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_maps = \"gen_maps\"\n",
    "SIZE = 8\n",
    "BORDER = 6\n",
    "X = []\n",
    "for folder in os.listdir(path_maps):\n",
    "    m = np.load(os.path.join(path_maps, folder, \"map.npy\"))\n",
    "    b = BORDER + 1\n",
    "    s = b+SIZE - 2\n",
    "    m = (m[b:s, b:s] -1) / 10\n",
    "    X.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.1, 0.8, 0.4, 0.4, 0.8],\n",
       "       [0.4, 0. , 0.3, 0.1, 0.6, 0.1],\n",
       "       [0.4, 0.1, 0.8, 0.1, 0.4, 0.8],\n",
       "       [0.1, 0.8, 0.1, 0.3, 0.8, 0.1],\n",
       "       [0.3, 0.1, 0.1, 0.1, 0. , 0.1],\n",
       "       [0.1, 0.4, 0. , 0.4, 0.4, 0.1]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[7:13, 7:13].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = tf.convert_to_tensor(data[\"balancing1\"])\n",
    "X = tf.convert_to_tensor(X)\n",
    "X = tf.expand_dims(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = y[:230]\n",
    "y_test = y[230:]\n",
    "X_train = X[:230]\n",
    "X_test = X[230:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_178 (Dense)           (None, 6, 16)             112       \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 96)                0         \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 16)                1552      \n",
      "                                                                 \n",
      " dense_180 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,681\n",
      "Trainable params: 1,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 2ms/step - loss: 0.1370\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1331\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1318\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1309\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1299\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1291\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1282\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1272\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1261\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1255\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1249\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1237\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1228\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1220\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1213\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1211\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1201\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1186\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1183\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1169\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1163\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1156\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1147\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1135\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1127\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1118\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1110\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1104\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1094\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1093\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1081\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1079\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1066\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1055\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1054\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1045\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1041\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1023\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1019\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1011\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.1004\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0995\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0985\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0981\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0974\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0964\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0952\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0947\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0938\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0940\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0921\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0918\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0916\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0895\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0887\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0878\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0872\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0863\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0855\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0847\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0837\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0830\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0822\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0813\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0803\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0796\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0799\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0782\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0789\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0770\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0762\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0753\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0742\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0738\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0724\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0725\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0716\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0706\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0694\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0707\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0676\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 0.0671\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0671\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0667\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0649\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0643\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0639\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0627\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0619\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0612\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0608\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0601\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0593\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0583\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0579\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0570\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0562\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0556\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ed907f4d90>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Input((6,6)))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.build()\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "model.fit(x=X_train, y=y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([300, 6, 6])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2d_25\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_25/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_25/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,32].\n\nCall arguments received by layer \"conv2d_25\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\FLORIA~1\\AppData\\Local\\Temp/ipykernel_19788/2228853319.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#model.add(tf.keras.layers.MaxPooling2D((2, 2)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian rupp\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian rupp\\envs\\lab\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\florian rupp\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1965\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m   \u001b[1;31m# Record the current Python stack trace as the creating stacktrace of this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_25\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_25/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_25/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,32].\n\nCall arguments received by layer \"conv2d_25\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input((6,6, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "#model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "#model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.build()\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "model.fit(x=X_train, y=y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14678235352039337"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(abs(model.predict(X_test) - y_test)[0]).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "0.25906664\n",
      "tf.Tensor(0.050000000000000044, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "print(model.predict(tf.expand_dims(X_test[i], axis=0))[0][0])\n",
    "print(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.3999999999999999>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1, 6), dtype=float64, numpy=\n",
       "array([[[0.1, 0.4, 0.1, 0.1, 0.6, 0.4]],\n",
       "\n",
       "       [[0.3, 0.1, 0.1, 0.8, 0.8, 0.1]],\n",
       "\n",
       "       [[0.8, 0.4, 0.3, 0.3, 0.4, 0. ]],\n",
       "\n",
       "       [[0.1, 0.3, 1. , 0.8, 0.1, 0.1]],\n",
       "\n",
       "       [[0. , 0.4, 0.8, 0.8, 0.4, 0. ]],\n",
       "\n",
       "       [[0.3, 0.6, 0.1, 0.1, 0.1, 0.1]]])>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(X_test[0], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
