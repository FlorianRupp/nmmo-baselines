{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>idx</th>\n",
       "      <th>balancing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  idx  balancing\n",
       "0           0    0       1.30\n",
       "1           1    1       2.00\n",
       "2           2    2       1.60\n",
       "3           3    3       1.55\n",
       "4           4    4       2.00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data[\"balancing\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    340\n",
       "idx           340\n",
       "balancing     340\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"balancing\"] == 1.5].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"balancing1\"] = data[\"balancing\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_maps = \"gen_maps\"\n",
    "SIZE = 8\n",
    "BORDER = 6\n",
    "X = []\n",
    "for folder in os.listdir(path_maps):\n",
    "    m = np.load(os.path.join(path_maps, folder, \"map.npy\"))\n",
    "    b = BORDER + 1\n",
    "    s = b+SIZE - 2\n",
    "    m = (m[b:s, b:s] -1) / 10\n",
    "    X.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.4, 0.4, 0.1, 0.1, 0.8],\n",
       "       [0.1, 0.3, 0.1, 0.3, 0. , 0.8],\n",
       "       [0.4, 0.1, 0.1, 0.3, 0.4, 0.8],\n",
       "       [0.8, 0.1, 0.4, 0.4, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.4, 0. , 0.1],\n",
       "       [0.8, 0.1, 0.1, 0.1, 0.1, 0.1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = tf.convert_to_tensor(data[\"balancing1\"])\n",
    "X = tf.convert_to_tensor(X)\n",
    "#X = tf.expand_dims(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split = int(len(X) * 0.8)\n",
    "y_train = y[:split]\n",
    "y_test = y[split:]\n",
    "X_train = X[:split]\n",
    "X_test = X[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 6, 16)             112       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 96)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                1552      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,681\n",
      "Trainable params: 1,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 786us/step - loss: 0.1351\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 802us/step - loss: 0.1338\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 833us/step - loss: 0.1333\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 848us/step - loss: 0.1330\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 850us/step - loss: 0.1328\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 826us/step - loss: 0.1322\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 848us/step - loss: 0.1319\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 843us/step - loss: 0.1315\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 771us/step - loss: 0.1307\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 758us/step - loss: 0.1305\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 723us/step - loss: 0.1297\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 762us/step - loss: 0.1295\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 704us/step - loss: 0.1285\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 727us/step - loss: 0.1282\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 864us/step - loss: 0.1273\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 766us/step - loss: 0.1268\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 750us/step - loss: 0.1261\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 763us/step - loss: 0.1253\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 744us/step - loss: 0.1246\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 775us/step - loss: 0.1240\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 755us/step - loss: 0.1229\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 769us/step - loss: 0.1222\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 759us/step - loss: 0.1213\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 791us/step - loss: 0.1206\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 766us/step - loss: 0.1207\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 752us/step - loss: 0.1189\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 780us/step - loss: 0.1182\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 747us/step - loss: 0.1173\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 831us/step - loss: 0.1168\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 925us/step - loss: 0.1167\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 899us/step - loss: 0.1150\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 770us/step - loss: 0.1148\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 759us/step - loss: 0.1135\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 741us/step - loss: 0.1129\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 747us/step - loss: 0.1125\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 767us/step - loss: 0.1114\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 799us/step - loss: 0.1107\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 766us/step - loss: 0.1101\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 821us/step - loss: 0.1094\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 747us/step - loss: 0.1086\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 744us/step - loss: 0.1081\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 0.1074\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 772us/step - loss: 0.1067\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 770us/step - loss: 0.1061\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 758us/step - loss: 0.1057\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 756us/step - loss: 0.1049\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 731us/step - loss: 0.1043\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 770us/step - loss: 0.1039\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 746us/step - loss: 0.1028\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 745us/step - loss: 0.1024\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 751us/step - loss: 0.1018\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 767us/step - loss: 0.1016\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 756us/step - loss: 0.1011\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 775us/step - loss: 0.1008\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 790us/step - loss: 0.1001\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 824us/step - loss: 0.0993\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 791us/step - loss: 0.0989\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 693us/step - loss: 0.0985\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 746us/step - loss: 0.0992\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 752us/step - loss: 0.0974\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 811us/step - loss: 0.0974\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 764us/step - loss: 0.0968\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 733us/step - loss: 0.0958\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 714us/step - loss: 0.0963\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 772us/step - loss: 0.0957\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 770us/step - loss: 0.0957\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 0.0945\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 736us/step - loss: 0.0939\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 789us/step - loss: 0.0938\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 745us/step - loss: 0.0931\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 750us/step - loss: 0.0930\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 750us/step - loss: 0.0928\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 783us/step - loss: 0.0921\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 788us/step - loss: 0.0917\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 744us/step - loss: 0.0911\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 733us/step - loss: 0.0915\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 753us/step - loss: 0.0908\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 735us/step - loss: 0.0901\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 770us/step - loss: 0.0898\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 764us/step - loss: 0.0898\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 744us/step - loss: 0.0896\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 820us/step - loss: 0.0894\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 878us/step - loss: 0.0888\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 855us/step - loss: 0.0885\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 766us/step - loss: 0.0876\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 726us/step - loss: 0.0875\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 748us/step - loss: 0.0870\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 767us/step - loss: 0.0870\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 772us/step - loss: 0.0871\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 798us/step - loss: 0.0863\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 731us/step - loss: 0.0857\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 749us/step - loss: 0.0858\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 744us/step - loss: 0.0849\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 794us/step - loss: 0.0848\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 743us/step - loss: 0.0839\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 759us/step - loss: 0.0844\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 739us/step - loss: 0.0836\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 758us/step - loss: 0.0834\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 774us/step - loss: 0.0828\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 722us/step - loss: 0.0823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd491c51e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Input((6,6)))\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.build()\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "model.fit(x=X_train, y=y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([300, 6, 6])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 32)          320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 2, 2, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2, 2, 1)           33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 353\n",
      "Trainable params: 353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 0s 997us/step - loss: 0.1341\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 942us/step - loss: 0.1339\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 959us/step - loss: 0.1341\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 979us/step - loss: 0.1340\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 895us/step - loss: 0.1339\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 966us/step - loss: 0.1339\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 949us/step - loss: 0.1339\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 963us/step - loss: 0.1340\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 981us/step - loss: 0.1340\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 887us/step - loss: 0.1340\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 936us/step - loss: 0.1343\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1340\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1339\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 904us/step - loss: 0.1339\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 920us/step - loss: 0.1338\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 915us/step - loss: 0.1339\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 926us/step - loss: 0.1340\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 912us/step - loss: 0.1338\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 941us/step - loss: 0.1339\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 922us/step - loss: 0.1338\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 938us/step - loss: 0.1339\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 934us/step - loss: 0.1339\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 908us/step - loss: 0.1340\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 893us/step - loss: 0.1340\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 884us/step - loss: 0.1338\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 894us/step - loss: 0.1340\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 948us/step - loss: 0.1338\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 937us/step - loss: 0.1338\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 928us/step - loss: 0.1338\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 882us/step - loss: 0.1339\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 898us/step - loss: 0.1338\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 933us/step - loss: 0.1338\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 967us/step - loss: 0.1339\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 915us/step - loss: 0.1339\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 938us/step - loss: 0.1339\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 946us/step - loss: 0.1340\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1339\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 947us/step - loss: 0.1338\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 961us/step - loss: 0.1339\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 916us/step - loss: 0.1338\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 955us/step - loss: 0.1339\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 968us/step - loss: 0.1341\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 928us/step - loss: 0.1338\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 922us/step - loss: 0.1338\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 985us/step - loss: 0.1338\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 994us/step - loss: 0.1338\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 986us/step - loss: 0.1338\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 947us/step - loss: 0.1338\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1339\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 942us/step - loss: 0.1338\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 951us/step - loss: 0.1338\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 918us/step - loss: 0.1338\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 936us/step - loss: 0.1338\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 915us/step - loss: 0.1338\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1338\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1338\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 996us/step - loss: 0.1339\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 913us/step - loss: 0.1338\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 960us/step - loss: 0.1338\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 941us/step - loss: 0.1338\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1338\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1338\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 971us/step - loss: 0.1338\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 926us/step - loss: 0.1338\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 934us/step - loss: 0.1341\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 891us/step - loss: 0.1339\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 923us/step - loss: 0.1339\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 883us/step - loss: 0.1338\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 924us/step - loss: 0.1339\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 892us/step - loss: 0.1338\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 915us/step - loss: 0.1338\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 914us/step - loss: 0.1338\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 908us/step - loss: 0.1338\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 905us/step - loss: 0.1338\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 882us/step - loss: 0.1338\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 997us/step - loss: 0.1338\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1338\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 923us/step - loss: 0.1338\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 913us/step - loss: 0.1338\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 922us/step - loss: 0.1339\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 906us/step - loss: 0.1338\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 885us/step - loss: 0.1338\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 903us/step - loss: 0.1338\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 915us/step - loss: 0.1338\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 886us/step - loss: 0.1338\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 890us/step - loss: 0.1338\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 888us/step - loss: 0.1338\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 889us/step - loss: 0.1338\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 939us/step - loss: 0.1337\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 911us/step - loss: 0.1338\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1338\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 922us/step - loss: 0.1338\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 946us/step - loss: 0.1337\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 908us/step - loss: 0.1337\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 925us/step - loss: 0.1338\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 931us/step - loss: 0.1338\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 910us/step - loss: 0.1338\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 895us/step - loss: 0.1338\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 986us/step - loss: 0.1338\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd459b7e50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input((6,6, 1)))\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "#model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "#model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "#model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "#model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "model.build()\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "model.fit(x=X_train, y=y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 833us/step - loss: 0.1403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14025883376598358"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 746us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(2, 2, 600)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [29]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mabs\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mplot\u001B[38;5;241m.\u001B[39mhist()\n",
      "File \u001B[1;32m~\\Envs\\work\\lib\\site-packages\\pandas\\core\\frame.py:737\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[1;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[0;32m    729\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m arrays_to_mgr(\n\u001B[0;32m    730\u001B[0m             arrays,\n\u001B[0;32m    731\u001B[0m             columns,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    734\u001B[0m             typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[0;32m    735\u001B[0m         )\n\u001B[0;32m    736\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 737\u001B[0m         mgr \u001B[38;5;241m=\u001B[39m \u001B[43mndarray_to_mgr\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    738\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    739\u001B[0m \u001B[43m            \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    740\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    741\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    742\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    743\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtyp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmanager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    744\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    745\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    746\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m dict_to_mgr(\n\u001B[0;32m    747\u001B[0m         {},\n\u001B[0;32m    748\u001B[0m         index,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    751\u001B[0m         typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[0;32m    752\u001B[0m     )\n",
      "File \u001B[1;32m~\\Envs\\work\\lib\\site-packages\\pandas\\core\\internals\\construction.py:331\u001B[0m, in \u001B[0;36mndarray_to_mgr\u001B[1;34m(values, index, columns, dtype, copy, typ)\u001B[0m\n\u001B[0;32m    326\u001B[0m         values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    328\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;66;03m# by definition an array here\u001B[39;00m\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;66;03m# the dtypes will be coerced to a single dtype\u001B[39;00m\n\u001B[1;32m--> 331\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43m_prep_ndarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy_on_sanitize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dtype_equal(values\u001B[38;5;241m.\u001B[39mdtype, dtype):\n\u001B[0;32m    334\u001B[0m     shape \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[1;32m~\\Envs\\work\\lib\\site-packages\\pandas\\core\\internals\\construction.py:591\u001B[0m, in \u001B[0;36m_prep_ndarray\u001B[1;34m(values, copy)\u001B[0m\n\u001B[0;32m    589\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mreshape((values\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m    590\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m values\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m--> 591\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMust pass 2-d input. shape=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mvalues\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    593\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m values\n",
      "\u001B[1;31mValueError\u001B[0m: Must pass 2-d input. shape=(2, 2, 600)"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(abs(model.predict(X_test) - y_test)[0]).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0222306\n",
      "tf.Tensor(1.0, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "print(model.predict(tf.expand_dims(X_test[i], axis=0))[0][0])\n",
    "print(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=1.0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 1, 6), dtype=float64, numpy=\n",
       "array([[[0.1, 0.4, 0.4, 0.6, 0. , 0.4]],\n",
       "\n",
       "       [[0.4, 0.1, 0.1, 0. , 0.1, 0.8]],\n",
       "\n",
       "       [[0.3, 0.8, 0. , 0.4, 0. , 0.1]],\n",
       "\n",
       "       [[0.1, 0. , 0.1, 0.1, 0.8, 0.1]],\n",
       "\n",
       "       [[0.1, 0.4, 0.8, 0.4, 0.1, 0.1]],\n",
       "\n",
       "       [[0.1, 0.1, 0.3, 0.4, 0.4, 0.1]]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(X_test[0], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
